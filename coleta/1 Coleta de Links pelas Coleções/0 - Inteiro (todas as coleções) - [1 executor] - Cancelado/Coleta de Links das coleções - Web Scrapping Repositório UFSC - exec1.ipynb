{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1uHB_tVNxBOeYEpUwrmYiXL0tPjC-utVq","timestamp":1697381955810},{"file_id":"1Sjsa-pZh9GhDqAiqmEvAS_ePE06Mz0Ua","timestamp":1697381901309}],"authorship_tag":"ABX9TyNPLF5jlNjHEIfkeaIX/rRF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Preparação do ambiente"],"metadata":{"id":"sUa0av70UapY"}},{"cell_type":"markdown","source":["**Execução 1** - baixando e importanto bibliotecas utilizadas ao decorrer da execução do programa"],"metadata":{"id":"fWCPlMKKUeXB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYt5CpmzUL1I"},"outputs":[],"source":["# Instalando as bibliotecas que serão utilizadas\n","try:\n","  !pip install requests\n","  !pip install beautifulsoup4\n","  !pip install pandas\n","  !pip install regex\n","  !pip install urllib3\n","except: # Caso ocorra algum erro ao instalar os pacotes/bibliotecas seremos notificados com uma mensagem na tela de output\n","  print('\\nErro ao instalar pacotes/bibliotecas.')\n","  print('Descrição do erro --> '+str(sys.exc_info()[0].__name__)+\": \"+str(sys.exc_info()[1])+'\\n')\n","else:\n","  from google.colab import drive\n","  from google.colab import output\n","  import requests\n","  from bs4 import BeautifulSoup\n","  import pandas as pd\n","  import time\n","  import re\n","  from urllib import request\n","  import os\n","  import sys\n","  execucao = True # Variável que armazenará o sucesso no download das bibliotecas\n","  output.clear()\n","  print('='*100)\n","  print('Bibliotecas carregadas!\\nPode executar o código abaixo.')\n","  print('='*100)"]},{"cell_type":"markdown","source":["**Execução 2** - Conectando ambiente do Google Colab ao Google Drive"],"metadata":{"id":"z7iWVlZ5Uz6J"}},{"cell_type":"code","source":["try:\n","  drive.mount('/content/drive')\n","except:\n","  print('\\nErro ao \"sincronizar\" Google Drive com este ambiente do Google Colab.\\nExecute a célula novamente ou tente \"montar\" o Drive manualmente no botão de \"Montar Drive\" no menu lateral esquerdo.')\n","  print('Descrição do erro --> '+str(sys.exc_info()[0].__name__)+\":\",str(sys.exc_info()[1])+'\\n')\n","  execucao = False\n","else:\n","  print('='*100)\n","  print('Drive conectado com sucesso.\\nPode prosseguir na execução das próximas células.')\n","  print('='*100)"],"metadata":{"id":"Yi8GVQsGU0JU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Execução 3** - Definindo variáveis e funções que serão utilizadas ao decorrer do programa"],"metadata":{"id":"9iaZhv0KU6B8"}},{"cell_type":"code","source":["if execucao:\n","\n","  headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \\\n","                (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36\"}\n","  timeout = 30\n","\n","  lista_de_falhas = {'Avisos':[],'Erros':[]}\n","\n","  try:\n","    def CriaDiretorio(caminho : str):\n","      try:\n","        os.makedirs(caminho)\n","        time.sleep(1)\n","        if os.path.isdir(caminho):\n","          print(f'Pasta {caminho} criada com sucesso.')\n","          return True\n","        else:\n","          print(f'Tentando criar pasta {caminho} novamente.')\n","          time.sleep(3)\n","          if os.path.isdir(caminho):\n","            print(f'Pasta {caminho} criada com sucesso.')\n","            return True\n","          else:\n","            print(f'Pasta {caminho} não foi carregada corretamente.')\n","            return False\n","      except:\n","        print(f'Erro ao criar diretório {caminho}.\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\": \"+str(sys.exc_info()[1])+'\\n')\n","        return False\n","\n","    def ColetaHTML(link_pagina : str):\n","      try:\n","        site = requests.get(link_pagina,headers=headers,timeout=timeout)\n","        if site.status_code == 200:\n","          soup = BeautifulSoup(site.content, 'html.parser')\n","          return True, soup\n","        else:\n","          print(f'Problema ao coletar HTML da página {link_pagina}.\\nsite.status_code != 200')\n","          return False, ''\n","      except:\n","        print(f'Problema ao coletar HTML da página {link_pagina}.\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\": \"+str(sys.exc_info()[1])+'.')\n","        return False, ''\n","\n","\n","    def ColetaNomesLinksColecoesDoHTML(soup):\n","      lista_nomes_colecoes = []\n","      lista_links_colecoes = []\n","\n","      campo_colecoes = soup.find('div', class_='ds-static-div secondary')\n","      if campo_colecoes != None:\n","        colecoes = campo_colecoes.find_all('li')\n","        if len(colecoes) == 0:\n","          print('\\nNão foi possível encontrar os elementos das coleções corretamente.')\n","          lista_de_falhas['Erros'].append('Não foi possível encontrar os elementos das coleções corretamente.')\n","          return False, '', ''\n","        else:\n","          print('Quantidade de coleções avistadas:',len(colecoes))\n","\n","          tamanho_total = len(colecoes)\n","          # metade_tamanho_total = int(tamanho_total/2)\n","\n","          for indice, colecao in enumerate(colecoes):\n","            nome_e_link_colecao = colecao.find('a', href=re.compile('/handle')) # Coletando o nome da coleção\n","            try:\n","              nome_colecao = nome_e_link_colecao.text\n","              lista_nomes_colecoes.append(nome_colecao)\n","\n","              link_colecao = nome_e_link_colecao['href']\n","              link_colecao = 'https://repositorio.ufsc.br'+link_colecao\n","              lista_links_colecoes.append(link_colecao)\n","            except:\n","              print(f'\\nErro ao encontrar o nome e link da coleção número {indice} da lista.\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\":\",str(sys.exc_info()[1])+'\\n')\n","              lista_de_falhas['Avisos'].append(f'Erro ao encontrar o nome e link da coleção número {indice} da lista.\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\": \"+str(sys.exc_info()[1])+'\\n')\n","            # break # Só vai pegar a primeira coleção\n","\n","            # Limitando número de coleções que serão visitadas\n","            # limite_colecoes = 3\n","            # if indice >= limite_colecoes:\n","            #   print(f'\\nLIMITE DE COLEÇÕES ({limite_colecoes+1}) ATINGIDO.')\n","            #   break\n","\n","          if lista_nomes_colecoes and lista_links_colecoes:\n","            return True, lista_nomes_colecoes, lista_links_colecoes\n","          else:\n","            return False, [], []\n","\n","      else:\n","        print('Campo de coleções não identificado corretamente na página. \"campo_colecoes == None\"!')\n","        return False,'',''\n","\n","    def ColetaLinksTrabalhosDoHTML(soup_colecao,link_principal_colecao):\n","      lista_links_trabalhos = []\n","      numero_paginas = soup_colecao.find('div', attrs={\"class\":'pagination-masked top'})\n","      if numero_paginas == None:\n","        print('\\nNão foi possível achar número de páginas corretamente.\\n(numero_paginas == None).')\n","        lista_de_falhas[\"Avisos\"].append(f'Não foi possível achar número de páginas corretamente da coleção {dic[\"Colecoes\"][i]} --> (numero_paginas == None).')\n","        return False, []\n","      else:\n","        paginas_links = numero_paginas.find('ul',class_='pagination-links')\n","        if paginas_links == None:\n","          print('\\nNão foi possível achar número de páginas corretamente.\\n(paginas_links == None)')\n","          lista_de_falhas[\"Avisos\"].append(f'Não foi possível achar número de páginas corretamente da coleção {dic[\"Colecoes\"][i]} --> (paginas_links == None).')\n","          return False, []\n","        else:\n","          links_pagina = paginas_links.find_all('li')\n","          if links_pagina == None:\n","            print('\\nNão foi possível achar número de páginas corretamente.\\n(links_pagina == None)')\n","            lista_de_falhas[\"Avisos\"].append(f'Não foi possível achar número de páginas corretamente da coleção {dic[\"Colecoes\"][i]} --> (links_pagina == None).')\n","            return False, []\n","          else:\n","            try:\n","              numero_paginas = int(links_pagina[len(links_pagina)-1].find('a').text)\n","            except:\n","              print('\\nNúmero de páginas não pode ser convertido para inteiro, logo foi setado como 1.\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\": \"+str(sys.exc_info()[1])+'\\n')\n","              numero_paginas = 1\n","              lista_de_falhas[\"Avisos\"].append(f'Número de páginas da coleção {dic[\"Colecoes\"][i]} não pode ser convertido para inteiro, logo foi setado como 1\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\": \"+str(sys.exc_info()[1])+'\\n')\n","            print('\\nNúmero total de páginas:',numero_paginas)\n","\n","\n","            links = soup_colecao.find_all('li', class_=re.compile('ds-artifact-item clearfix'))\n","            if len(links) == 0:\n","              print('\\nNão foi possível encontrar corretamente os links para os trabalhos.')\n","              lista_de_falhas[\"Avisos\"].append(f'Não foi possível encontrar/captar corretamente os links para os trabalhos da coleção {dic[\"Colecoes\"][i]}.')\n","              return False, []\n","            else:\n","              pagina = 1\n","\n","              while(pagina <= numero_paginas):\n","                print('\\nIndo para página:',pagina)\n","                link_p_trabalhos = link_principal_colecao + f'/discover?rpp=50&etal=0&group_by=none&page={pagina}'\n","      #                                  MUDAR O RPP = 50 PARA RPP = 100  QUANDO FOR FAZER NO REPOSITÓRIO TODO (falar com TI da BU antes) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","                status_conteudo_HTML_links_trabalho, soup_links_trabalho = ColetaHTML(link_p_trabalhos)\n","                if status_conteudo_HTML_links_trabalho:\n","                  links = soup_links_trabalho.find_all('li', class_=re.compile('ds-artifact-item clearfix'))\n","                  if len(links) == 0:\n","                    print(f'\\nNão foi possível encontrar corretamente os links dos resultados da coleção {dic[\"Colecoes\"][i]} no link: \"{link}\".')\n","                    lista_de_falhas['Avisos'].append(f'Não foi possível encontrar/coletar corretamente os links dos resultados da coleção {dic[\"Colecoes\"][i]} no link: \"{link}\".')\n","                  else:\n","                    for links_trabalho in links:\n","                      link_trabalho = links_trabalho.find('a', href=re.compile('/handle'))\n","                      if link_trabalho != None:\n","                        link_trabalho = link_trabalho['href']\n","                        link_trabalho = 'https://repositorio.ufsc.br'+link_trabalho\n","                        lista_links_trabalhos.append(link_trabalho)\n","                      else:\n","                        print(f'\\nLink do trabalho não foi encontrado corretamente. Coleção: {dic[\"Colecoes\"][i]}, link: \"{link}\".')\n","                        lista_de_falhas['Avisos'].append(f'Link do trabalho não foi encontrado corretamente. Coleção: {dic[\"Colecoes\"][i]}, link: \"{link}\".')\n","\n","                  # # Limitando a busca (primeiramente não vamos passar por todos os resultados)\n","                  # limite_pagina = 2\n","                  # if pagina >= limite_pagina:\n","                  #   print(f'\\nLIMITE DE PÁGINAS ({limite_pagina}) ALCANÇADO.')\n","                  #   break\n","                  # else:\n","                  #   pagina += 1\n","                  pagina += 1\n","              return True, lista_links_trabalhos\n","\n","  except:\n","    print('Erro ao criar funções.\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\": \"+str(sys.exc_info()[1])+'\\n')\n","  else:\n","    print('='*100)\n","    print('Variáveis para requisições e funções de criação de diretório criadas com sucesso.\\nPode dar continuidade na execução das células abaixo.')\n","    print('='*100)\n","else:\n","  print('\\nFalha no carregamento das bibliotecas ou sincronização com Drive. Tente executar as primeiras células de códigos novamente.')"],"metadata":{"id":"EOGCBaCwU5ia"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Execução das ações, de fato"],"metadata":{"id":"oxr2uTYLVFIl"}},{"cell_type":"markdown","source":["**Execução 4** - Criação de pasta \"Coleções Repositorio UFSC\" e sub-pasta \"Links dos trabalhos - Repositorio UFSC\" para armazenamento dos primeiros dados (links das coleções)"],"metadata":{"id":"LKSAMCEuU_Sh"}},{"cell_type":"code","source":["if execucao:\n","  try:\n","    # CriaDiretorio(\"/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Extração de Dados/via Web Scraping/Resultados/Coleções Repositorio UFSC/Links dos trabalhos - Repositorio UFSC\")\n","    CriaDiretorio(\"/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Extração de Dados/via Web Scraping/Otimizações/Resultados/Coleções Repositorio UFSC/Links dos trabalhos - Repositorio UFSC\")\n","  except:\n","    print('\\nErro ao criar pasta no Drive com o código do Google Colab.\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\":\",str(sys.exc_info()[1])+'\\n')\n","    execucao = False\n","  else:\n","    print('='*100)\n","    print('Pastas de trabalhos \"Coleções Repositorio UFSC\" e \"Links dos trabalhos - Repositorio UFSC\" criadas com sucesso!\\nPode continuar e executar os códigos abaixo.')\n","    print('='*100)\n","else:\n","  print('\\nFalha no carregamento das bibliotecas. Tente executar a primeira célula de códigos novamente.\\n')"],"metadata":{"id":"GpRRqMMQU-mG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Execução 5** - Preenchimento de dados (links) das coleções e dos trabalhos de cada coleção"],"metadata":{"id":"_oEngsfmVPSZ"}},{"cell_type":"code","source":["if execucao:\n","\n","  start = time.time()\n","\n","\n","  link = 'https://repositorio.ufsc.br/handle/123456789/74645'\n","\n","  status_conteudo_HTML, soup_repositorio = ColetaHTML(link)\n","  if status_conteudo_HTML:\n","    numero_total_de_trabalhos = 0\n","    dic = {'Colecoes':[],'Links colecoes':[]}\n","    lista_links_trabalhos = []\n","\n","    status_info_HTML,lista_nomes_colecoes,lista_links_colecoes = ColetaNomesLinksColecoesDoHTML(soup_repositorio)\n","    if status_info_HTML:\n","      dic['Colecoes'] = lista_nomes_colecoes\n","      dic['Links colecoes'] = lista_links_colecoes\n","      print('\\nNúmero de coleções encontradas:',len(dic['Links colecoes']))\n","      num_colecao = 0\n","\n","\n","      for i in range(len(dic['Links colecoes'])):\n","        dic_trabalho = {'Links trabalhos':[]}\n","        num_colecao +=1\n","        link_principal_colecao = dic['Links colecoes'][i]\n","\n","        link_colecao_atual = link_principal_colecao + '/discover?rpp=50&etal=0&group_by=none&page=1'\n","    #                                  MUDAR O RPP = 50 PARA RPP = 100  QUANDO FOR FAZER NO REPOSITÓRIO TODO (falar com TI da BU antes) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n","\n","        status_conteudo_HTML, soup_colecao = ColetaHTML(link_colecao_atual)\n","        if status_conteudo_HTML:\n","          status_links_trabalhos, lista_links_trabalhos = ColetaLinksTrabalhosDoHTML(soup_colecao,link_principal_colecao)\n","          if status_links_trabalhos:\n","            dic_trabalho['Links trabalhos'] = lista_links_trabalhos\n","            numero_total_de_trabalhos += len(lista_links_trabalhos)\n","            print('\\nNúmero de links coletados:',len(dic_trabalho[\"Links trabalhos\"]))\n","\n","            try:\n","              df = pd.DataFrame(dic_trabalho)\n","            except:\n","              print('Problemas ao transformar o dicionário \"dic_trabalho\" num dataframe pandas.')\n","            else:\n","              if '/' in dic[\"Colecoes\"][i]:\n","                index = dic[\"Colecoes\"][i].find('/')\n","                dic[\"Colecoes\"][i] = dic[\"Colecoes\"][i][:index]+'_'+dic[\"Colecoes\"][i][index+1:]\n","              if ':' in dic[\"Colecoes\"][i]:\n","                index = dic[\"Colecoes\"][i].find(':')\n","                dic[\"Colecoes\"][i] = dic[\"Colecoes\"][i][:index]+' '+dic[\"Colecoes\"][i][index+1:]\n","              try:\n","                df.to_csv(f'/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Extração de Dados/via Web Scraping/Otimizações/Resultados/Coleções Repositorio UFSC/Links dos trabalhos - Repositorio UFSC/{dic[\"Colecoes\"][i]}_Links_dos_Trabalhos.csv',index=False,encoding='utf-8',sep=',')\n","              except:\n","                print(f'\\nErro ao fazer download do arquivo .csv para coleção {dic[\"Colecoes\"][i]}.\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\":\",str(sys.exc_info()[1])+'\\n')\n","                lista_de_falhas['Erros'].append(f'Erro ao fazer download do arquivo .csv para coleção {dic[\"Colecoes\"][i]}.\\nDescrição do erro --> '+str(sys.exc_info()[0].__name__)+\": \"+str(sys.exc_info()[1])+'\\n')\n","              else:\n","                print(f'\\nDownload do arquivo .csv da coleção {dic[\"Colecoes\"][i]} feito com sucesso!\\n')\n","\n","\n","        # # Código abaixo comentado, pois era apenas para fins de limitar o número de coleções que serão visitadas\n","        # num_colecao_maxima = 4\n","        # if num_colecao >= num_colecao_maxima-1:\n","        #   print(f'\\nParou na {num_colecao}a coleção.')\n","        #   break\n","\n","  print('\\n')\n","  print('='*100)\n","  print('Programa executado com sucesso!\\nNúmero total de links de trabalhos coletados:',numero_total_de_trabalhos)\n","  print(f'Número de Coleções visitadas:',len(dic[\"Links colecoes\"]))\n","  print('='*100)\n","  print('\\n')\n","  print('='*100)\n","  print('Número de avisos gerados:',len(lista_de_falhas[\"Avisos\"]))\n","  print('Número de erros gerados:',len(lista_de_falhas[\"Erros\"]))\n","  print('='*100)\n","\n","\n","  if (len(lista_de_falhas['Avisos']) > 0):\n","    file_path = '/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Extração de Dados/via Web Scraping/Otimizações/Resultados/Coleções Repositorio UFSC/Links dos trabalhos - Repositorio UFSC/AVISOS primeira metade.txt'\n","    texto = 'AVISOS:\\n\\n'\n","    for i in range(len(lista_de_falhas['Avisos'])):\n","      texto = texto + '\\n' + lista_de_falhas['Avisos'][i]\n","    with open(file_path, 'w') as f:\n","      f.write(texto)\n","      print('\\nArquivo de avisos salvo com sucesso.\\nVerifique-o!')\n","      f.close()\n","  if (len(lista_de_falhas['Erros']) > 0):\n","    file_path = '/content/drive/MyDrive/Programa - Repositório Institucional UFSC/Extração de Dados/via Web Scraping/Otimizações/Resultados/Coleções Repositorio UFSC/Links dos trabalhos - Repositorio UFSC/ERROS primeira metade.txt'\n","    texto = 'ERROS:\\n\\n'\n","    for i in range(len(lista_de_falhas['Erros'])):\n","      texto = texto + '\\n' + lista_de_falhas['Erros'][i]\n","    with open(file_path, 'w') as f:\n","      f.write(texto)\n","      print('\\nArquivo de erros salvo com sucesso.\\nVerifique-o!')\n","      f.close()\n","\n","  end = time.time()\n","\n","  duracao = end - start\n","  print('\\n')\n","  print('='*100)\n","  print('Duração total da primeira execução:',round(duracao,2))\n","  print('='*100)\n","else:\n","  print('\\nFalha na execução das células anteriores. Volte, leia as saídas das células anteriores e tente executá-las novamente.\\n')"],"metadata":{"id":"8HclKfz_VP1c"},"execution_count":null,"outputs":[]}]}